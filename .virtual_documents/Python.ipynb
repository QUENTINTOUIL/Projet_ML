








# Chargement des librairies nécessaires
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.metrics import classification_report
from sklearn.tree import DecisionTreeClassifier
from sklearn.tree import plot_tree
from sklearn.ensemble import RandomForestClassifier










# Lecture des données
path = ""
gym = pd.read_csv("gym_members_exercise_tracking.csv")

# Affichage des premières lignes
print("Aperçu des premières lignes du jeu de données:")
display(gym.head())  

# Résumé statistique
print("\nRésumé statistique du jeu de données:")
display(gym.describe(include='all'))  





print(gym.columns.tolist())


# Nettoyage des noms de colonnes : suppression des unités entre parenthèses et espaces
gym.columns = (
    gym.columns
    .str.replace(r"\s*\(.*?\)", "", regex=True)  # Supprime tout ce qui est entre parenthèses
    .str.replace(" ", "_")                      # Remplace les espaces par des underscores
)



print(gym.columns.tolist())


# Conversion des colonnes en types catégoriels
categorical_columns = [
    "Gender",
    "Workout_Type",
    "Experience_Level",
    "Workout_Frequency"
]

for col in categorical_columns:
    gym[col] = gym[col].astype("category")









# Application du logarithme sur les colonnes 'Weight..kg.' et 'BMI'
gym["LWeight"] = np.log(gym["Weight"])
gym["LBMI"] = np.log(gym["BMI"])

# Supprimer les colonnes originales
gym.drop(columns=["Weight", "BMI"], inplace=True)


print("\nRésumé statistique du jeu de données:")
display(gym.describe(include='all'))  











#Variables qualitatives
qual_vars = gym.select_dtypes(include="category").columns.tolist()
gymDum = pd.get_dummies(gym[qual_vars], drop_first=True)
print(qual_vars)



gymQuant=gym[['Age', 'Height', 'Max_BPM', 'Avg_BPM', 'Resting_BPM', 'Session_Duration',  'Fat_Percentage', 'Water_Intake',  'LWeight', 'LBMI']]
dfC=pd.concat([gymDum,gymQuant],axis=1)
dfC.head()

# variable à expliquer réelle
Yr=gym["Calories_Burned"]


from sklearn.model_selection import train_test_split  
X_train, X_test, Yr_train, Yr_test = train_test_split(dfC, Yr, test_size=0.2, random_state=235)


Yr.hist()
plt.show()





from sklearn.preprocessing import StandardScaler  
# L'algorithme des réseaux de neurones nécessite éventuellement une normalisation 
# des variables explicatives avec les commandes ci-dessous
scaler = StandardScaler()  
scaler.fit(X_train)
Xr_train = scaler.transform(X_train)  
# Meme transformation sur le test
Xr_test = scaler.transform(X_test)














from sklearn import linear_model
from sklearn.metrics import mean_squared_error
regLasso = linear_model.Lasso()
regLasso.fit(Xr_train,Yr_train)
prev=regLasso.predict(Xr_test)
print("MSE=",mean_squared_error(Yr_test,prev))


from sklearn.metrics import r2_score
print("R2=",r2_score(Yr_test,prev))





from sklearn.model_selection import GridSearchCV

# grille de valeurs du paramètre alpha à optimiser
param=[{"alpha":[0.5,0.8,1,3, 3, 4.52]}]
regLasso = GridSearchCV(linear_model.Lasso(), param,cv=10,n_jobs=-1)
regLassOpt=regLasso.fit(Xr_train, Yr_train)


# paramètre optimal
regLassOpt.best_params_["alpha"]
print("Meilleur R2 = %f, Meilleur paramètre = %s" % (regLassOpt.best_score_,regLassOpt.best_params_))


# Résultats de prédiction sur l'échantillon de test
prev=regLassOpt.predict(Xr_test)
mse_mod_lin_lasso=mean_squared_error(prev,Yr_test)
r2_mod_lin_lasso=r2_score(Yr_test,prev)
print("MSE=", mse_mod_lin_lasso)
print("R2=",r2_mod_lin_lasso)


# Coefficients gardés par Lasso
regLasso=linear_model.Lasso(alpha=regLassOpt.best_params_['alpha'])
model_lasso=regLasso.fit(Xr_train,Yr_train)
model_lasso.coef_
coef = pd.Series(model_lasso.coef_, index = X_train.columns)
print("Lasso conserve " + str(sum(coef != 0)) + 
      " variables et en supprime " +  str(sum(coef == 0)))


# Résidus sur l'échantillon de test
plt.plot(prev,Yr_test-prev,"o")
plt.xlabel(u"Prédites")
plt.ylabel(u"Résidus")
plt.hlines(0,40,1600)
plt.show()


#Importance des paramètres
imp_coef = coef.sort_values()
plt.rcParams['figure.figsize'] = (8.0, 10.0)
imp_coef.plot(kind = "barh")
plt.title("Coefficients du modèle lasso")














from sklearn.svm import SVR



# Définition du modèle SVR et des hyperparamètres à tester
svr = SVR()
param_grid = {
    'C': [3.5,5, 8, 12, 20,50, 100, 120],
    'gamma': ['scale', 'auto', 0.001, 0.01, 0.1, 1]
}

# Grid Search avec validation croisée
grid_search = GridSearchCV(svr, param_grid, cv=10)
grid_search.fit(Xr_train, Yr_train)

# Meilleur modèle
best_svr = grid_search.best_estimator_
print("Meilleurs paramètres trouvés :", grid_search.best_params_)



# Prédiction sur les jeux de données
Yr_train_pred = best_svr.predict(Xr_train)
Yr_test_pred = best_svr.predict(Xr_test)

# Calcul des résidus
residus_train = Yr_train - Yr_train_pred
residus_test = Yr_test - Yr_test_pred

# Tracé des résidus
plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
plt.scatter(Yr_train_pred, residus_train, color='blue', alpha=0.5)
plt.axhline(y=0, color='red', linestyle='--')
plt.title("Résidus sur jeu d'entraînement")
plt.xlabel("Valeurs prédites")
plt.ylabel("Résidus")

plt.subplot(1, 2, 2)
plt.scatter(Yr_test_pred, residus_test, color='green', alpha=0.5)
plt.axhline(y=0, color='red', linestyle='--')
plt.title("Résidus sur jeu de test")
plt.xlabel("Valeurs prédites")
plt.ylabel("Résidus")

plt.tight_layout()
plt.show()





# Résultats de prédiction sur l'échantillon de test

mse_svr=mean_squared_error(Yr_test_pred,Yr_test)
r2_svr=r2_score(Yr_test,Yr_test_pred)
print("MSE=", mse_mod_lin_lasso)
print("R2=",r2_mod_lin_lasso)









































































































































cat("RMSE RdN :",sqrt(erreur_RDN),"\n")
cat("RMSE Boosting :",sqrt(erreur_boosting),"\n")
cat("RMSE Foret aléatoire :" ,sqrt(erreur_randomforest),"\n")
cat("RMSE Arbre optimal :",sqrt(erreur_arbreoptimal) ,"\n")
cat("RMSE pour un SVR avec noyau radial :",sqrt(erreur_SVR) , "\n")
cat("RMSE Modèle linéaire Lasso avec lambda.min :", sqrt(mse.lasso.min), "\n")
cat("RMSE Modèle linéaire  Lasso avec lambda.1se :", sqrt(mse.lasso.1se), "\n")
cat("RMSE modèle linéaire sans sélection de variable :", sqrt(mse.lm), "\n")





















GymDum=pd.get_dummies(gym[["Gender","Workout_Type","Experience_Level","Workout_Frequency"]])
GymDum = GymDum.drop(columns=["Workout_Type_Cardio","Workout_Frequency_2"])


GymDum2=pd.get_dummies(gym[["Gender","Workout_Type","Workout_Frequency"]])
GymDum2 = GymDum2.drop(columns=["Workout_Type_Cardio","Workout_Frequency_2"])


Y1=GymDum["Experience_Level_1"]
Y2=GymDum["Experience_Level_2"]
Y3=GymDum["Experience_Level_3"]

Yb=gym["Experience_Level"]

Y1.head()


dfC2=pd.concat([GymDum,gymQuant],axis=1)
dfC2=dfC2.drop(columns=["Experience_Level_1","Experience_Level_2", "Experience_Level_3"]) 

dfC3=pd.concat([GymDum2,gymQuant],axis=1)

dfC2.head()





X1_train,X1_test,Y1_train,Y1_test=train_test_split(dfC2,Y1,test_size=0.2,random_state=17)
X2_train,X2_test,Y2_train,Y2_test=train_test_split(dfC2,Y2,test_size=0.2,random_state=17)
X3_train,X3_test,Y3_train,Y3_test=train_test_split(dfC2,Y3,test_size=0.2,random_state=17)
X_train,X_test,Yb_train,Yb_test=train_test_split(dfC3,Yb,test_size=0.2,random_state=17)





scaler = StandardScaler()  
scaler.fit(X1_train)  
scaler.fit(X2_train)  
scaler.fit(X3_train)  
scaler.fit(X_train)  

Xb1_train = scaler.fit_transform(X1_train)  
Xb1_test = scaler.transform(X1_test)
Xb2_train = scaler.fit_transform(X2_train)  
Xb2_test = scaler.transform(X2_test)
Xb3_train = scaler.fit_transform(X3_train)  
Xb3_test = scaler.transform(X3_test)
Xb_train = scaler.fit_transform(X_train)  
Xb_test = scaler.transform(X_test)

















from sklearn.svm import SVC


param=[{"C":[0.4,0.5,0.6,0.8,1,1.4,2,2.5]}]
svm= GridSearchCV(SVC(probability=True),param,cv=10,n_jobs=-1)
svmOpt=svm.fit(Xb_train, Yb_train)

# paramètre optimal
print("Meilleur score = %f, Meilleur paramètre = %s" % (1. - svmOpt.best_score_,svmOpt.best_params_))





# erreur de prévision sur le test
precision_SVM=svmOpt.score(Xb_test,Yb_test)
1-precision_SVM


# prévision de l'échantillon test
y_pred_test = svmOpt.predict(Xb_test)
# matrice de confusion
table=pd.crosstab(y_pred_test ,Yb_test)
print("Matrice de confusion: ")
print(table)

print("")
print("")

print("Rapport de classification: ")
print(classification_report(Yb_test, y_pred_test))








# Optimisation de la profondeur de l'arbre
param=[{"max_depth":list(range(2,12))}]
tree= GridSearchCV(DecisionTreeClassifier(),param,cv=10,n_jobs=-1)
treeOpt=tree.fit(Xb_train, Yb_train)

# paramètre optimal
print("Meilleur score = %f, Meilleur paramètre = %s" % (1. - treeOpt.best_score_,treeOpt.best_params_))



best_tree=DecisionTreeClassifier(max_depth=treeOpt.best_params_['max_depth'])
best_tree.fit(Xb_train,Yb_train)
plot_tree(best_tree,feature_names=dfC.columns.tolist());
plt.show()


# Estimation de l'erreur de prévision
precision_CART=treeOpt.score(Xb_test,Yb_test)
1-precision_CART


# prévision de l'échantillon test
y_pred_test_CART = treeOpt.predict(Xb_test)

# matrice de confusion
print("Matrice de confusion CART : ")
table=pd.crosstab(y_pred_test_CART,Yb_test)
print((pd.DataFrame(table)))

print("")
print("")

print("Rapport de classification CART : ")
print(classification_report(Yb_test, y_pred_test_CART))





param=[{"max_features":list(range(2,10,1))}]
rf= GridSearchCV(RandomForestClassifier(n_estimators=100),
        param,cv=5,n_jobs=-1)
rfOpt=rf.fit(Xb_train, Yb_train)
# paramètre optimal
print("Meilleur score = %f, Meilleur paramètre = %s" % (1. - rfOpt.best_score_,rfOpt.best_params_))





# erreur de prévision sur le test
precision_RandomForest=rfOpt.score(Xb_test,Yb_test)


# prévision
y_pred_rf = rfOpt.predict(Xb_test)
# matrice de confusion
print("Matrice de confusion: ")
table=pd.crosstab(y_pred_rf,Yb_test)
print(table)

print("")
print("")

print("Rapport de classification: ")
print(classification_report(Yb_test, y_pred_rf))















